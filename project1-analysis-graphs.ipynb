{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/scratch/group/csce435-f24/python-3.10.4/lib/python3.10/site-packages\")\n",
    "sys.path.append(\"/scratch/group/csce435-f24/thicket\")\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import thicket as th\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1_trial is a name of a folder containing the cali files, you may create a folder with a different name and replace the folder name here\n",
    "tkSorted = th.Thicket.from_caliperreader(glob(\"caliper_files/Sorted/*.cali\"));\n",
    "tkRandom = th.Thicket.from_caliperreader(glob(\"caliper_files/Random/*.cali\"));\n",
    "tkReverse = th.Thicket.from_caliperreader(glob(\"caliper_files/ReverseSorted/*.cali\"));\n",
    "tkPerturbed = th.Thicket.from_caliperreader(glob(\"caliper_files/1_perc_perturbed/*.cali\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(tkSorted.tree(metric_column=\"Avg time/rank\", precision=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(tkRandom.tree(metric_column=\"Avg time/rank\", precision=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tkReverse.tree(metric_column=\"Avg time/rank\", precision=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tkPerturbed.tree(metric_column=\"Avg time/rank\", precision=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkRandom.metadata_column_to_perfdata(\"num_procs\")\n",
    "tkRandom.metadata_column_to_perfdata(\"input_size\")\n",
    "\n",
    "tkRandom.dataframe = tkRandom.dataframe.reset_index().set_index([\"node\", \"num_procs\", \"input_size\"]).sort_index()\n",
    "\n",
    "tkSorted.metadata_column_to_perfdata(\"num_procs\")\n",
    "tkSorted.metadata_column_to_perfdata(\"input_size\")\n",
    "\n",
    "tkSorted.dataframe = tkSorted.dataframe.reset_index().set_index([\"node\", \"num_procs\", \"input_size\"]).sort_index()\n",
    "\n",
    "tkReverse.metadata_column_to_perfdata(\"num_procs\")\n",
    "tkReverse.metadata_column_to_perfdata(\"input_size\")\n",
    "\n",
    "tkReverse.dataframe = tkReverse.dataframe.reset_index().set_index([\"node\", \"num_procs\", \"input_size\"]).sort_index()\n",
    "\n",
    "tkPerturbed.metadata_column_to_perfdata(\"num_procs\")\n",
    "tkPerturbed.metadata_column_to_perfdata(\"input_size\")\n",
    "\n",
    "tkPerturbed.dataframe = tkPerturbed.dataframe.reset_index().set_index([\"node\", \"num_procs\", \"input_size\"]).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c. Min/Max/Avg/Total/Variance Time per Rank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leg = [\"MIN\", \"AVG\", \"MAX\"]\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "def plot_mpl(df, df2, df3, title, xlabel, ylabel, input_type):    \n",
    "    for input_size in df.columns:\n",
    "        if (input_size != 268435456) and (input_size != 65536):\n",
    "            continue\n",
    "        fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.plot(processes, df[input_size], marker='o', label='Min')\n",
    "        ax.plot(processes, df2[input_size], marker='o', label='Avg')\n",
    "        ax.plot(processes, df3[input_size], marker='o', label='Max')\n",
    "\n",
    "        ax.set_title(f\"{title}, {input_type}, Input size: {input_size}\")\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.legend(leg)\n",
    "        plt.xscale(\"log\", base=2)\n",
    "        plt.xticks(processes)\n",
    "        ax.set_xticklabels(processes)\n",
    "        \n",
    "#         plt.show()\n",
    "        directory = f\"part4_graphs/{input_type}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"{directory}/{title}_{input_type}_inputsize_{input_size}.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close(fig)\n",
    "        \n",
    "def plot_mplOne(df, title, xlabel, ylabel, typ, input_type):    \n",
    "    for input_size in df.columns:\n",
    "        if (input_size != 268435456) and (input_size != 65536):\n",
    "            continue\n",
    "        fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.plot(processes, df[input_size], marker='o')\n",
    "        ax.set_title(f\"{title} {typ}, {input_type}, Input size: {input_size}\")\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        plt.xscale(\"log\", base=2)\n",
    "        plt.xticks(processes)\n",
    "        ax.set_xticklabels(processes)\n",
    "        \n",
    "#         plt.show()\n",
    "        directory = f\"part4_graphs/{input_type}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"{directory}/{title}_{typ}_{input_type}_{input_size}.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close(fig)\n",
    "        \n",
    "def plot_mplSpeedup(df, title, xlabel, ylabel, typ, input_type):    \n",
    "    baseline = df.loc[2];\n",
    "    for input_size in df.columns:\n",
    "        if (input_size != 268435456) and (input_size != 65536):\n",
    "            continue\n",
    "        fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.plot(processes, baseline[input_size] / df[input_size], marker='o')\n",
    "        ax.set_title(f\"{title} {typ}, {input_type}, Input size: {input_size}\")\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        plt.xscale(\"log\", base=2)\n",
    "        plt.xticks(processes)\n",
    "        ax.set_xticklabels(processes)\n",
    "        \n",
    "#         plt.show()\n",
    "        directory = f\"part4_graphs/{input_type}\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"{directory}/{title}_{typ}_{input_type}_{input_size}.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close(fig)\n",
    "        \n",
    "input_types = ['Random', 'Sorted', 'Reverse', 'Perturbed']\n",
    "thickets = [tkRandom, tkSorted, tkReverse, tkPerturbed]\n",
    "\n",
    "for tk, input_type in zip(thickets, input_types):\n",
    "    for node in tk.graph.traverse():\n",
    "        if node.frame[\"name\"] not in ['main', 'comp_large', 'comm']:\n",
    "            continue\n",
    "        \n",
    "        plot_mpl(\n",
    "            df=tk.dataframe.loc[node, \"Min time/rank\"].unstack(level=\"input_size\"),\n",
    "            df2=tk.dataframe.loc[node, \"Avg time/rank\"].unstack(level=\"input_size\"),\n",
    "            df3=tk.dataframe.loc[node, \"Max time/rank\"].unstack(level=\"input_size\"),\n",
    "            title=node.frame[\"name\"],\n",
    "            xlabel=\"Processes\",\n",
    "            ylabel=\"Time (seconds)\",\n",
    "            input_type=input_type\n",
    "        )\n",
    "        \n",
    "        plot_mplOne(\n",
    "            df=tk.dataframe.loc[node, \"Total time\"].unstack(level=\"input_size\"),\n",
    "            title=node.frame[\"name\"],\n",
    "            xlabel=\"Processes\",\n",
    "            ylabel=\"Time (seconds)\",\n",
    "            typ=\"Total Time\",\n",
    "            input_type=input_type\n",
    "        )\n",
    "        \n",
    "        plot_mplOne(\n",
    "            df=tk.dataframe.loc[node, \"Variance time/rank\"].unstack(level=\"input_size\"),\n",
    "            title=node.frame[\"name\"],\n",
    "            xlabel=\"Processes\",\n",
    "            ylabel=\"Time (seconds)\",\n",
    "            typ=\"Variance\",\n",
    "            input_type=input_type\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For comp_large, comm, main: Strong scaling plots for each input_size with lines for input_type (7 plots - 4 lines each)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg = [\"Random\", \"Sorted\", \"Reverse\", \"Perturbed\"]\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "def plot_comparison(df_random, df_sorted, df_reverse, df_perturbed, title, xlabel, ylabel):    \n",
    "    for input_size in df_random.columns:\n",
    "        fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        \n",
    "        ax.plot(processes, df_random[input_size], marker='o', label='Random')\n",
    "        ax.plot(processes, df_sorted[input_size], marker='s', label='Sorted')\n",
    "        ax.plot(processes, df_reverse[input_size], marker='^', label='Reverse')\n",
    "        ax.plot(processes, df_perturbed[input_size], marker='D', label='Perturbed')\n",
    "        \n",
    "        ax.set_title(f\"{title}, Input size: {input_size}\")\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "        plt.xscale(\"log\", base=2)\n",
    "        plt.xticks(processes)\n",
    "        ax.set_xticklabels(processes)\n",
    "        \n",
    "        directory = f\"part5_graphs/strong_scaling\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        filename = f\"{directory}/{title}_{input_size}.png\"\n",
    "        plt.savefig(filename)\n",
    "        \n",
    "#         plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "for node in tkRandom.graph.traverse():\n",
    "    if node.frame[\"name\"] not in ['main', 'comp_large', 'comm']:\n",
    "        continue\n",
    "    \n",
    "    node_sorted = next(n for n in tkSorted.graph.traverse() \n",
    "                      if n.frame[\"name\"] == node.frame[\"name\"])\n",
    "    node_reverse = next(n for n in tkReverse.graph.traverse() \n",
    "                       if n.frame[\"name\"] == node.frame[\"name\"])\n",
    "    node_perturbed = next(n for n in tkPerturbed.graph.traverse() \n",
    "                         if n.frame[\"name\"] == node.frame[\"name\"])\n",
    "    \n",
    "    plot_comparison(\n",
    "        df_random=tkRandom.dataframe.loc[node, \"Avg time/rank\"].unstack(level=\"input_size\"),\n",
    "        df_sorted=tkSorted.dataframe.loc[node_sorted, \"Avg time/rank\"].unstack(level=\"input_size\"),\n",
    "        df_reverse=tkReverse.dataframe.loc[node_reverse, \"Avg time/rank\"].unstack(level=\"input_size\"),\n",
    "        df_perturbed=tkPerturbed.dataframe.loc[node_perturbed, \"Avg time/rank\"].unstack(level=\"input_size\"),\n",
    "        title=node.frame[\"name\"],\n",
    "        xlabel=\"Processes\",\n",
    "        ylabel=\"Time (seconds)\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strong scaling speedup plot for each input_type (4 plots)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strong_scaling_speedup(df, input_type, processes, node_name):\n",
    "    input_sizes = sorted(df.columns)\n",
    "    fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(input_sizes)))\n",
    "    \n",
    "    for i, input_size in enumerate(input_sizes):\n",
    "        baseline = df[input_size].iloc[0]\n",
    "        speedup = (baseline / df[input_size]) * 2\n",
    "        \n",
    "        ax.plot(processes, speedup, marker='o', label=f'N={input_size}', \n",
    "                color=colors[i], linewidth=2, markersize=6)\n",
    "    \n",
    "    ax.set_title(f\"Strong Scaling Speedup - {input_type} - {node_name}\")\n",
    "    ax.set_xlabel(\"Processes\")\n",
    "    ax.set_ylabel(\"Speedup\")\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_yscale('log', base=2)\n",
    "    ax.set_xticks(processes)\n",
    "    ax.get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "#     plt.show()\n",
    "    directory = f\"part5_graphs/speedup\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"{directory}/strong_scaling_{input_type}_{node_name}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "for tk, input_type in zip([tkRandom, tkSorted, tkReverse, tkPerturbed], ['Random', 'Sorted', 'Reverse', 'Perturbed']):\n",
    "    for node in tk.graph.traverse():\n",
    "        if node.frame[\"name\"] not in ['main', 'comp_large', 'comm']:\n",
    "            continue\n",
    "        node_name = node.frame[\"name\"]\n",
    "        df = tk.dataframe.loc[node, \"Avg time/rank\"].unstack(level=\"input_size\")\n",
    "        df = df.loc[processes]\n",
    "        \n",
    "        plot_strong_scaling_speedup(df, input_type, processes, node_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weak scaling plots for each input_type (4 plots)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Takes inputs sizes with a constant workload per processor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names = ['main', 'comp_large', 'comm']\n",
    "\n",
    "input_types = ['Random', 'Sorted', 'ReverseSorted', '1_perc_perturbed']\n",
    "thickets = [tkRandom, tkSorted, tkReverse, tkPerturbed]\n",
    "\n",
    "process_input_pairs = {\n",
    "    2: 65536,\n",
    "    8: 262144,\n",
    "    32: 1048576,\n",
    "    128: 4194304,\n",
    "    512: 16777216\n",
    "}\n",
    "\n",
    "def plot_weak_scaling(tk, input_type, node_name, process_input_pairs):\n",
    "    df = tk.dataframe\n",
    "\n",
    "    try:\n",
    "        node = next(n for n in tk.graph.traverse() if n.frame[\"name\"] == node_name)\n",
    "    except StopIteration:\n",
    "        print(f\"Node {node_name} not found in input type {input_type}\")\n",
    "        return\n",
    "\n",
    "    df_node = df.loc[node, \"Avg time/rank\"].unstack(level=\"input_size\")\n",
    "    times = []\n",
    "    processes_used = []\n",
    "\n",
    "    for num_procs, input_size in process_input_pairs.items():\n",
    "        if num_procs not in df_node.index:\n",
    "            continue\n",
    "        if input_size not in df_node.columns:\n",
    "            continue\n",
    "        time = df_node[input_size].loc[num_procs]\n",
    "        if pd.isna(time):\n",
    "            continue\n",
    "        times.append(time)\n",
    "        processes_used.append(num_procs)\n",
    "\n",
    "    if not times:\n",
    "        print(f\"No data available for {node_name} with input type {input_type}\")\n",
    "        return\n",
    "\n",
    "    fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(processes_used, times, marker='o', label='Weak Scaling')\n",
    "\n",
    "    ax.set_title(f\"Weak Scaling - {input_type} - {node_name}\")\n",
    "    ax.set_xlabel(\"Processes\")\n",
    "    ax.set_ylabel(\"Time (seconds)\")\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_xticks(processes_used)\n",
    "    ax.get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "#     plt.show()\n",
    "    directory = f\"part5_graphs/weak_scaling\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"{directory}/weak_scaling_{node_name}_{input_type}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "for tk, input_type in zip([tkRandom, tkSorted, tkReverse, tkPerturbed], ['Random', 'Sorted', 'ReverseSorted', '1_perc_perturbed']):\n",
    "    for node_name in node_names:\n",
    "        plot_weak_scaling(tk, input_type, node_name, process_input_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:03<00:00, 21.78it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 30.84it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 39.05it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:03<00:00, 21.96it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 38.97it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 29.10it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 39.08it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 31.91it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 35.27it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 33.61it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 42.40it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 33.79it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 41.06it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 30.75it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 42.40it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 33.59it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 40.27it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 32.55it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 35.43it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 32.79it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 40.62it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 33.31it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 41.22it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 32.20it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 35.69it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 33.48it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 41.42it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 34.20it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 42.40it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 30.04it/s]\n",
      "(1/2) Reading Files: 100%|██████████| 70/70 [00:01<00:00, 40.91it/s]\n",
      "(2/2) Creating Thicket: 100%|██████████| 69/69 [00:02<00:00, 33.42it/s]\n"
     ]
    }
   ],
   "source": [
    "sorting_algorithms = ['sample', 'radix', 'bitonic', 'merge']\n",
    "input_types = ['Random', 'Sorted', 'ReverseSorted', '1_perc_perturbed']\n",
    "processes = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "thickets = {}\n",
    "\n",
    "base_dir = 'all_caliper'\n",
    "\n",
    "for sort_algo in sorting_algorithms:\n",
    "    thickets[sort_algo] = {}\n",
    "    for input_type in input_types:\n",
    "        pattern = os.path.join(base_dir, sort_algo, input_type, '*.cali')\n",
    "        cali_files = glob(pattern)\n",
    "        if not cali_files:\n",
    "            continue\n",
    "        thicket = th.Thicket.from_caliperreader(cali_files)\n",
    "        thicket.metadata_column_to_perfdata(\"num_procs\")\n",
    "        thicket.metadata_column_to_perfdata(\"input_size\")\n",
    "        thicket.dataframe = thicket.dataframe.reset_index().set_index([\"node\", \"num_procs\", \"input_size\"]).sort_index()\n",
    "        thickets[sort_algo][input_type] = thicket\n",
    "\n",
    "input_sizes = [65536, 262144, 1048576, 4194304, 16777216, 67108864, 268435456]\n",
    "\n",
    "node_names = ['comm', 'comp_large', 'main']\n",
    "\n",
    "def plot_avg_time_rank(thickets, input_type, node_name, input_size, processes):\n",
    "    fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    colors = ['blue', 'green', 'red', 'purple']\n",
    "    markers = ['o', 's', '^', 'D']\n",
    "    \n",
    "    sort_algo_names = ['Sample Sort', 'Radix Sort', 'Bitonic Sort', 'Merge Sort']\n",
    "    \n",
    "    for idx, sort_algo in enumerate(sorting_algorithms):\n",
    "        if input_type not in thickets[sort_algo]:\n",
    "            continue\n",
    "        thicket = thickets[sort_algo][input_type]\n",
    "        node = next((n for n in thicket.graph.traverse() if n.frame[\"name\"] == node_name), None)\n",
    "        if node is None:\n",
    "            continue\n",
    "        df = thicket.dataframe.loc[node, \"Avg time/rank\"].unstack(level=\"input_size\")\n",
    "        if df.empty:\n",
    "            continue\n",
    "        df = df.loc[processes]\n",
    "        if input_size not in df.columns:\n",
    "            continue\n",
    "        times = df[input_size]\n",
    "        if times.isnull().all():\n",
    "            continue\n",
    "        ax.plot(processes, times, marker=markers[idx], color=colors[idx], label=sort_algo_names[idx])\n",
    "    \n",
    "    ax.set_title(f\"{node_name}, {input_type.replace('_', ' ')}, Input size: {input_size}\")\n",
    "    ax.set_xlabel(\"Processes\")\n",
    "    ax.set_ylabel(\"Average Time per Rank (seconds)\")\n",
    "    ax.legend()\n",
    "    ax.set_xscale(\"log\", base=2)\n",
    "    ax.set_xticks(processes)\n",
    "    ax.set_xticklabels(processes)\n",
    "    ax.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "    \n",
    "    directory = os.path.join('combined_graphs', input_type, node_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"{node_name}_{input_type}_{input_size}.png\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    plt.savefig(filepath, facecolor=fig.get_facecolor())  # Include facecolor\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_speedup(thickets, input_type, node_name, input_size, processes):\n",
    "    fig = plt.figure(figsize=(15,7), facecolor=(1, 1, 1))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    colors = ['blue', 'green', 'red', 'purple']\n",
    "    markers = ['o', 's', '^', 'D']\n",
    "    \n",
    "    sort_algo_names = ['Sample Sort', 'Radix Sort', 'Bitonic Sort', 'Merge Sort']\n",
    "    \n",
    "    for idx, sort_algo in enumerate(sorting_algorithms):\n",
    "        if input_type not in thickets[sort_algo]:\n",
    "            continue\n",
    "        thicket = thickets[sort_algo][input_type]\n",
    "        node = next((n for n in thicket.graph.traverse() if n.frame[\"name\"] == node_name), None)\n",
    "        if node is None:\n",
    "            continue\n",
    "        df = thicket.dataframe.loc[node, \"Avg time/rank\"].unstack(level=\"input_size\")\n",
    "        if df.empty:\n",
    "            continue\n",
    "        df = df.loc[processes]\n",
    "        if input_size not in df.columns:\n",
    "            continue\n",
    "        times = df[input_size]\n",
    "        if times.isnull().any():\n",
    "            continue\n",
    "        if 2 not in times.index:\n",
    "            continue\n",
    "        baseline = times.loc[2]\n",
    "        speedup = (baseline / times) * 2\n",
    "        ax.plot(processes, speedup, marker=markers[idx], color=colors[idx], label=sort_algo_names[idx])\n",
    "    \n",
    "    ax.set_title(f\"Speedup - {node_name}, {input_type.replace('_', ' ')}, Input size: {input_size}\")\n",
    "    ax.set_xlabel(\"Processes\")\n",
    "    ax.set_ylabel(\"Speedup\")\n",
    "    ax.legend()\n",
    "    ax.set_xscale(\"log\", base=2)\n",
    "    ax.set_xticks(processes)\n",
    "    ax.set_xticklabels(processes)\n",
    "    \n",
    "#     plt.show()\n",
    "    directory = os.path.join('combined_graphs', input_type, 'speedup')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = f\"{node_name}_speedup_{input_type}_{input_size}.png\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    plt.savefig(filepath, facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "\n",
    "for input_type in input_types:\n",
    "    for input_size in input_sizes:\n",
    "        for node_name in node_names:\n",
    "            plot_avg_time_rank(thickets, input_type, node_name, input_size, processes)\n",
    "            plot_speedup(thickets, input_type, node_name, input_size, processes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
